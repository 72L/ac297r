<html><head><title>Copy of FINAL REPORT (text lock)</title><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url('https://themes.googleusercontent.com/fonts/css?kit=OPeqXG-QxW3ZD8BtmPikfA');ol.lst-kix_sdf0j17e1jp-5.start{counter-reset:lst-ctn-kix_sdf0j17e1jp-5 0}.lst-kix_87x65jl259tk-4>li:before{content:"\0025cb  "}.lst-kix_gxp9ru7mkj9d-5>li:before{content:"" counter(lst-ctn-kix_gxp9ru7mkj9d-5,lower-roman) ". "}.lst-kix_fp64b4k8l2ok-6>li:before{content:"-  "}.lst-kix_5dmkh3qp8ptx-5>li:before{content:"" counter(lst-ctn-kix_5dmkh3qp8ptx-5,lower-roman) ". "}.lst-kix_ecyay2i3donq-5>li:before{content:"" counter(lst-ctn-kix_ecyay2i3donq-5,lower-roman) ". "}.lst-kix_fp64b4k8l2ok-7>li:before{content:"-  "}.lst-kix_87x65jl259tk-1>li:before{content:"\0025cb  "}.lst-kix_xorjrjr9v1ea-3>li:before{content:"\0025cf  "}.lst-kix_sdf0j17e1jp-2>li{counter-increment:lst-ctn-kix_sdf0j17e1jp-2}.lst-kix_q4jiliohojpc-2>li:before{content:"\0025a0  "}ol.lst-kix_gxp9ru7mkj9d-2.start{counter-reset:lst-ctn-kix_gxp9ru7mkj9d-2 0}ol.lst-kix_ecyay2i3donq-1.start{counter-reset:lst-ctn-kix_ecyay2i3donq-1 0}.lst-kix_m9fqt5w4ua93-8>li:before{content:"\0025a0  "}.lst-kix_87x65jl259tk-5>li:before{content:"\0025a0  "}.lst-kix_gxp9ru7mkj9d-5>li{counter-increment:lst-ctn-kix_gxp9ru7mkj9d-5}.lst-kix_ecyay2i3donq-2>li{counter-increment:lst-ctn-kix_ecyay2i3donq-2}.lst-kix_nx633fdz6tnz-0>li:before{content:"Topic " counter(lst-ctn-kix_nx633fdz6tnz-0,decimal) ": "}.lst-kix_5becfkkgwd3c-1>li:before{content:"\0025cb  "}.lst-kix_5dmkh3qp8ptx-8>li:before{content:"" counter(lst-ctn-kix_5dmkh3qp8ptx-8,lower-roman) ". "}.lst-kix_w7067k58rhkv-1>li:before{content:"\0025cb  "}.lst-kix_xorjrjr9v1ea-2>li:before{content:"\0025a0  "}.lst-kix_ecyay2i3donq-1>li:before{content:"" counter(lst-ctn-kix_ecyay2i3donq-1,lower-latin) ". "}.lst-kix_5dmkh3qp8ptx-2>li{counter-increment:lst-ctn-kix_5dmkh3qp8ptx-2}.lst-kix_nx633fdz6tnz-8>li:before{content:"\0025a0  "}ol.lst-kix_5dmkh3qp8ptx-2.start{counter-reset:lst-ctn-kix_5dmkh3qp8ptx-2 0}ol.lst-kix_nx633fdz6tnz-0.start{counter-reset:lst-ctn-kix_nx633fdz6tnz-0 0}.lst-kix_gxp9ru7mkj9d-3>li:before{content:"" counter(lst-ctn-kix_gxp9ru7mkj9d-3,decimal) ". "}.lst-kix_87x65jl259tk-8>li:before{content:"\0025a0  "}.lst-kix_5dmkh3qp8ptx-7>li{counter-increment:lst-ctn-kix_5dmkh3qp8ptx-7}.lst-kix_5becfkkgwd3c-7>li:before{content:"\0025cb  "}.lst-kix_ecyay2i3donq-4>li:before{content:"" counter(lst-ctn-kix_ecyay2i3donq-4,lower-latin) ". "}ol.lst-kix_sdf0j17e1jp-8.start{counter-reset:lst-ctn-kix_sdf0j17e1jp-8 0}.lst-kix_gxp9ru7mkj9d-1>li{counter-increment:lst-ctn-kix_gxp9ru7mkj9d-1}.lst-kix_m9fqt5w4ua93-1>li:before{content:"\0025cb  "}ol.lst-kix_sdf0j17e1jp-2.start{counter-reset:lst-ctn-kix_sdf0j17e1jp-2 0}.lst-kix_w7067k58rhkv-5>li:before{content:"\0025a0  "}.lst-kix_m9fqt5w4ua93-5>li:before{content:"\0025a0  "}ol.lst-kix_xorjrjr9v1ea-0{list-style-type:none}.lst-kix_gxp9ru7mkj9d-4>li{counter-increment:lst-ctn-kix_gxp9ru7mkj9d-4}.lst-kix_q4jiliohojpc-3>li:before{content:"\0025cf  "}.lst-kix_xorjrjr9v1ea-0>li{counter-increment:lst-ctn-kix_xorjrjr9v1ea-0}.lst-kix_q4jiliohojpc-5>li:before{content:"\0025a0  "}.lst-kix_ecyay2i3donq-0>li{counter-increment:lst-ctn-kix_ecyay2i3donq-0}ol.lst-kix_xorjrjr9v1ea-0.start{counter-reset:lst-ctn-kix_xorjrjr9v1ea-0 0}.lst-kix_5dmkh3qp8ptx-5>li{counter-increment:lst-ctn-kix_5dmkh3qp8ptx-5}.lst-kix_5dmkh3qp8ptx-4>li:before{content:"" counter(lst-ctn-kix_5dmkh3qp8ptx-4,lower-latin) ". "}.lst-kix_gxp9ru7mkj9d-3>li{counter-increment:lst-ctn-kix_gxp9ru7mkj9d-3}.lst-kix_w7067k58rhkv-4>li:before{content:"\0025cb  "}.lst-kix_gxp9ru7mkj9d-2>li{counter-increment:lst-ctn-kix_gxp9ru7mkj9d-2}.lst-kix_xorjrjr9v1ea-8>li:before{content:"\0025a0  "}.lst-kix_ecyay2i3donq-8>li:before{content:"" counter(lst-ctn-kix_ecyay2i3donq-8,lower-roman) ". "}.lst-kix_q4jiliohojpc-4>li:before{content:"\0025cb  "}.lst-kix_sdf0j17e1jp-0>li:before{content:"" counter(lst-ctn-kix_sdf0j17e1jp-0,decimal) ". "}.lst-kix_nx633fdz6tnz-6>li:before{content:"\0025cf  "}.lst-kix_ecyay2i3donq-2>li:before{content:"" counter(lst-ctn-kix_ecyay2i3donq-2,lower-roman) ". "}.lst-kix_gxp9ru7mkj9d-7>li{counter-increment:lst-ctn-kix_gxp9ru7mkj9d-7}.lst-kix_nx633fdz6tnz-4>li:before{content:"\0025cb  "}.lst-kix_w7067k58rhkv-8>li:before{content:"\0025a0  "}.lst-kix_fp64b4k8l2ok-4>li:before{content:"-  "}.lst-kix_87x65jl259tk-6>li:before{content:"\0025cf  "}.lst-kix_5becfkkgwd3c-0>li:before{content:"\0025cf  "}.lst-kix_gxp9ru7mkj9d-8>li{counter-increment:lst-ctn-kix_gxp9ru7mkj9d-8}.lst-kix_sdf0j17e1jp-5>li:before{content:"" counter(lst-ctn-kix_sdf0j17e1jp-5,lower-roman) ". "}.lst-kix_gxp9ru7mkj9d-8>li:before{content:"" counter(lst-ctn-kix_gxp9ru7mkj9d-8,lower-roman) ". "}.lst-kix_sdf0j17e1jp-8>li{counter-increment:lst-ctn-kix_sdf0j17e1jp-8}ol.lst-kix_5dmkh3qp8ptx-3.start{counter-reset:lst-ctn-kix_5dmkh3qp8ptx-3 0}.lst-kix_fp64b4k8l2ok-0>li:before{content:"-  "}ol.lst-kix_ecyay2i3donq-7.start{counter-reset:lst-ctn-kix_ecyay2i3donq-7 0}ol.lst-kix_sdf0j17e1jp-1.start{counter-reset:lst-ctn-kix_sdf0j17e1jp-1 0}.lst-kix_5becfkkgwd3c-8>li:before{content:"\0025a0  "}ol.lst-kix_gxp9ru7mkj9d-4.start{counter-reset:lst-ctn-kix_gxp9ru7mkj9d-4 0}ol.lst-kix_gxp9ru7mkj9d-6.start{counter-reset:lst-ctn-kix_gxp9ru7mkj9d-6 0}.lst-kix_sdf0j17e1jp-6>li:before{content:"" counter(lst-ctn-kix_sdf0j17e1jp-6,decimal) ". "}.lst-kix_ecyay2i3donq-1>li{counter-increment:lst-ctn-kix_ecyay2i3donq-1}.lst-kix_fp64b4k8l2ok-1>li:before{content:"-  "}.lst-kix_xorjrjr9v1ea-6>li:before{content:"\0025cf  "}ol.lst-kix_ecyay2i3donq-4.start{counter-reset:lst-ctn-kix_ecyay2i3donq-4 0}ul.lst-kix_xorjrjr9v1ea-7{list-style-type:none}ul.lst-kix_xorjrjr9v1ea-6{list-style-type:none}ul.lst-kix_xorjrjr9v1ea-5{list-style-type:none}ul.lst-kix_xorjrjr9v1ea-4{list-style-type:none}ol.lst-kix_5dmkh3qp8ptx-6.start{counter-reset:lst-ctn-kix_5dmkh3qp8ptx-6 0}.lst-kix_nx633fdz6tnz-7>li:before{content:"\0025cb  "}ol.lst-kix_gxp9ru7mkj9d-1{list-style-type:none}.lst-kix_5dmkh3qp8ptx-0>li{counter-increment:lst-ctn-kix_5dmkh3qp8ptx-0}ol.lst-kix_gxp9ru7mkj9d-0{list-style-type:none}ul.lst-kix_xorjrjr9v1ea-8{list-style-type:none}ol.lst-kix_gxp9ru7mkj9d-3{list-style-type:none}ol.lst-kix_gxp9ru7mkj9d-2{list-style-type:none}ol.lst-kix_gxp9ru7mkj9d-5{list-style-type:none}ol.lst-kix_gxp9ru7mkj9d-4{list-style-type:none}.lst-kix_gxp9ru7mkj9d-0>li{counter-increment:lst-ctn-kix_gxp9ru7mkj9d-0}ol.lst-kix_gxp9ru7mkj9d-7{list-style-type:none}ul.lst-kix_xorjrjr9v1ea-3{list-style-type:none}ol.lst-kix_gxp9ru7mkj9d-6{list-style-type:none}ul.lst-kix_xorjrjr9v1ea-2{list-style-type:none}ul.lst-kix_xorjrjr9v1ea-1{list-style-type:none}.lst-kix_nx633fdz6tnz-5>li:before{content:"\0025a0  "}ol.lst-kix_gxp9ru7mkj9d-8{list-style-type:none}.lst-kix_xorjrjr9v1ea-4>li:before{content:"\0025cb  "}.lst-kix_q4jiliohojpc-6>li:before{content:"\0025cf  "}.lst-kix_fp64b4k8l2ok-3>li:before{content:"-  "}ul.lst-kix_87x65jl259tk-8{list-style-type:none}ul.lst-kix_87x65jl259tk-6{list-style-type:none}ul.lst-kix_87x65jl259tk-7{list-style-type:none}ul.lst-kix_87x65jl259tk-4{list-style-type:none}ol.lst-kix_gxp9ru7mkj9d-3.start{counter-reset:lst-ctn-kix_gxp9ru7mkj9d-3 0}ul.lst-kix_87x65jl259tk-5{list-style-type:none}ul.lst-kix_87x65jl259tk-2{list-style-type:none}ul.lst-kix_87x65jl259tk-3{list-style-type:none}ul.lst-kix_87x65jl259tk-0{list-style-type:none}.lst-kix_5becfkkgwd3c-3>li:before{content:"\0025cf  "}ul.lst-kix_87x65jl259tk-1{list-style-type:none}.lst-kix_5dmkh3qp8ptx-3>li:before{content:"" counter(lst-ctn-kix_5dmkh3qp8ptx-3,decimal) ". "}.lst-kix_5dmkh3qp8ptx-3>li{counter-increment:lst-ctn-kix_5dmkh3qp8ptx-3}.lst-kix_nx633fdz6tnz-3>li:before{content:"\0025cf  "}ol.lst-kix_ecyay2i3donq-0.start{counter-reset:lst-ctn-kix_ecyay2i3donq-0 0}.lst-kix_xorjrjr9v1ea-0>li:before{content:"Topic " counter(lst-ctn-kix_xorjrjr9v1ea-0,decimal) ": "}.lst-kix_m9fqt5w4ua93-2>li:before{content:"\0025a0  "}.lst-kix_sdf0j17e1jp-7>li:before{content:"" counter(lst-ctn-kix_sdf0j17e1jp-7,lower-latin) ". "}.lst-kix_5becfkkgwd3c-4>li:before{content:"\0025cb  "}.lst-kix_w7067k58rhkv-3>li:before{content:"\0025cf  "}ol.lst-kix_nx633fdz6tnz-0{list-style-type:none}.lst-kix_gxp9ru7mkj9d-2>li:before{content:"" counter(lst-ctn-kix_gxp9ru7mkj9d-2,lower-roman) ". "}ol.lst-kix_sdf0j17e1jp-3.start{counter-reset:lst-ctn-kix_sdf0j17e1jp-3 0}.lst-kix_w7067k58rhkv-7>li:before{content:"\0025cb  "}ul.lst-kix_fp64b4k8l2ok-8{list-style-type:none}.lst-kix_sdf0j17e1jp-6>li{counter-increment:lst-ctn-kix_sdf0j17e1jp-6}.lst-kix_gxp9ru7mkj9d-4>li:before{content:"" counter(lst-ctn-kix_gxp9ru7mkj9d-4,lower-latin) ". "}ul.lst-kix_fp64b4k8l2ok-5{list-style-type:none}.lst-kix_m9fqt5w4ua93-7>li:before{content:"\0025cb  "}.lst-kix_ecyay2i3donq-7>li:before{content:"" counter(lst-ctn-kix_ecyay2i3donq-7,lower-latin) ". "}ul.lst-kix_fp64b4k8l2ok-4{list-style-type:none}ul.lst-kix_q4jiliohojpc-7{list-style-type:none}ul.lst-kix_fp64b4k8l2ok-7{list-style-type:none}ul.lst-kix_q4jiliohojpc-8{list-style-type:none}ul.lst-kix_fp64b4k8l2ok-6{list-style-type:none}ul.lst-kix_q4jiliohojpc-5{list-style-type:none}ul.lst-kix_fp64b4k8l2ok-1{list-style-type:none}ul.lst-kix_q4jiliohojpc-6{list-style-type:none}ul.lst-kix_fp64b4k8l2ok-0{list-style-type:none}ul.lst-kix_q4jiliohojpc-3{list-style-type:none}ul.lst-kix_fp64b4k8l2ok-3{list-style-type:none}ul.lst-kix_q4jiliohojpc-4{list-style-type:none}ul.lst-kix_fp64b4k8l2ok-2{list-style-type:none}ul.lst-kix_q4jiliohojpc-1{list-style-type:none}ul.lst-kix_q4jiliohojpc-2{list-style-type:none}.lst-kix_ecyay2i3donq-6>li{counter-increment:lst-ctn-kix_ecyay2i3donq-6}.lst-kix_5becfkkgwd3c-6>li:before{content:"\0025cf  "}ul.lst-kix_q4jiliohojpc-0{list-style-type:none}ol.lst-kix_ecyay2i3donq-6.start{counter-reset:lst-ctn-kix_ecyay2i3donq-6 0}.lst-kix_nx633fdz6tnz-2>li:before{content:"\0025a0  "}.lst-kix_fp64b4k8l2ok-2>li:before{content:"-  "}ol.lst-kix_5dmkh3qp8ptx-8.start{counter-reset:lst-ctn-kix_5dmkh3qp8ptx-8 0}.lst-kix_nx633fdz6tnz-0>li{counter-increment:lst-ctn-kix_nx633fdz6tnz-0}.lst-kix_gxp9ru7mkj9d-0>li:before{content:"" counter(lst-ctn-kix_gxp9ru7mkj9d-0,decimal) ". "}ol.lst-kix_ecyay2i3donq-3.start{counter-reset:lst-ctn-kix_ecyay2i3donq-3 0}ol.lst-kix_5dmkh3qp8ptx-0{list-style-type:none}ol.lst-kix_5dmkh3qp8ptx-1{list-style-type:none}ol.lst-kix_5dmkh3qp8ptx-2{list-style-type:none}.lst-kix_87x65jl259tk-0>li:before{content:"\0025cf  "}ol.lst-kix_5dmkh3qp8ptx-3{list-style-type:none}ol.lst-kix_5dmkh3qp8ptx-5{list-style-type:none}ol.lst-kix_ecyay2i3donq-2{list-style-type:none}ol.lst-kix_5dmkh3qp8ptx-4{list-style-type:none}ol.lst-kix_ecyay2i3donq-3{list-style-type:none}ol.lst-kix_5dmkh3qp8ptx-7{list-style-type:none}ol.lst-kix_ecyay2i3donq-0{list-style-type:none}ol.lst-kix_5dmkh3qp8ptx-6{list-style-type:none}ol.lst-kix_ecyay2i3donq-1{list-style-type:none}ol.lst-kix_ecyay2i3donq-6{list-style-type:none}ol.lst-kix_5dmkh3qp8ptx-8{list-style-type:none}ol.lst-kix_ecyay2i3donq-7{list-style-type:none}ol.lst-kix_ecyay2i3donq-4{list-style-type:none}.lst-kix_87x65jl259tk-7>li:before{content:"\0025cb  "}ol.lst-kix_ecyay2i3donq-5{list-style-type:none}ol.lst-kix_ecyay2i3donq-8{list-style-type:none}ol.lst-kix_sdf0j17e1jp-5{list-style-type:none}ol.lst-kix_sdf0j17e1jp-4{list-style-type:none}ol.lst-kix_sdf0j17e1jp-7{list-style-type:none}ul.lst-kix_nx633fdz6tnz-8{list-style-type:none}ol.lst-kix_sdf0j17e1jp-6{list-style-type:none}ul.lst-kix_nx633fdz6tnz-7{list-style-type:none}ol.lst-kix_sdf0j17e1jp-8{list-style-type:none}ol.lst-kix_gxp9ru7mkj9d-1.start{counter-reset:lst-ctn-kix_gxp9ru7mkj9d-1 0}ol.lst-kix_sdf0j17e1jp-1{list-style-type:none}ol.lst-kix_sdf0j17e1jp-0{list-style-type:none}ol.lst-kix_sdf0j17e1jp-3{list-style-type:none}.lst-kix_5dmkh3qp8ptx-6>li{counter-increment:lst-ctn-kix_5dmkh3qp8ptx-6}ol.lst-kix_sdf0j17e1jp-2{list-style-type:none}ol.lst-kix_5dmkh3qp8ptx-7.start{counter-reset:lst-ctn-kix_5dmkh3qp8ptx-7 0}.lst-kix_xorjrjr9v1ea-7>li:before{content:"\0025cb  "}ul.lst-kix_m9fqt5w4ua93-6{list-style-type:none}ul.lst-kix_m9fqt5w4ua93-7{list-style-type:none}ul.lst-kix_m9fqt5w4ua93-8{list-style-type:none}ol.lst-kix_sdf0j17e1jp-6.start{counter-reset:lst-ctn-kix_sdf0j17e1jp-6 0}ol.lst-kix_ecyay2i3donq-5.start{counter-reset:lst-ctn-kix_ecyay2i3donq-5 0}ol.lst-kix_gxp9ru7mkj9d-8.start{counter-reset:lst-ctn-kix_gxp9ru7mkj9d-8 0}ol.lst-kix_gxp9ru7mkj9d-0.start{counter-reset:lst-ctn-kix_gxp9ru7mkj9d-0 0}.lst-kix_w7067k58rhkv-2>li:before{content:"\0025a0  "}.lst-kix_fp64b4k8l2ok-5>li:before{content:"-  "}.lst-kix_5dmkh3qp8ptx-1>li{counter-increment:lst-ctn-kix_5dmkh3qp8ptx-1}ol.lst-kix_sdf0j17e1jp-0.start{counter-reset:lst-ctn-kix_sdf0j17e1jp-0 0}.lst-kix_sdf0j17e1jp-8>li:before{content:"" counter(lst-ctn-kix_sdf0j17e1jp-8,lower-roman) ". "}.lst-kix_5dmkh3qp8ptx-6>li:before{content:"" counter(lst-ctn-kix_5dmkh3qp8ptx-6,decimal) ". "}ul.lst-kix_5becfkkgwd3c-4{list-style-type:none}ul.lst-kix_m9fqt5w4ua93-5{list-style-type:none}ol.lst-kix_ecyay2i3donq-8.start{counter-reset:lst-ctn-kix_ecyay2i3donq-8 0}ol.lst-kix_ecyay2i3donq-2.start{counter-reset:lst-ctn-kix_ecyay2i3donq-2 0}ul.lst-kix_5becfkkgwd3c-5{list-style-type:none}ul.lst-kix_m9fqt5w4ua93-4{list-style-type:none}ul.lst-kix_5becfkkgwd3c-6{list-style-type:none}ul.lst-kix_m9fqt5w4ua93-3{list-style-type:none}ul.lst-kix_5becfkkgwd3c-7{list-style-type:none}ul.lst-kix_m9fqt5w4ua93-2{list-style-type:none}ul.lst-kix_5becfkkgwd3c-0{list-style-type:none}ul.lst-kix_m9fqt5w4ua93-1{list-style-type:none}ul.lst-kix_5becfkkgwd3c-1{list-style-type:none}ul.lst-kix_m9fqt5w4ua93-0{list-style-type:none}ul.lst-kix_5becfkkgwd3c-2{list-style-type:none}ul.lst-kix_5becfkkgwd3c-3{list-style-type:none}.lst-kix_sdf0j17e1jp-0>li{counter-increment:lst-ctn-kix_sdf0j17e1jp-0}ul.lst-kix_5becfkkgwd3c-8{list-style-type:none}.lst-kix_5becfkkgwd3c-2>li:before{content:"\0025a0  "}ul.lst-kix_nx633fdz6tnz-1{list-style-type:none}ul.lst-kix_nx633fdz6tnz-2{list-style-type:none}ul.lst-kix_nx633fdz6tnz-3{list-style-type:none}.lst-kix_nx633fdz6tnz-1>li:before{content:"\0025cb  "}ul.lst-kix_nx633fdz6tnz-4{list-style-type:none}ul.lst-kix_nx633fdz6tnz-5{list-style-type:none}ul.lst-kix_nx633fdz6tnz-6{list-style-type:none}.lst-kix_q4jiliohojpc-0>li:before{content:"\0025cf  "}.lst-kix_87x65jl259tk-3>li:before{content:"\0025cf  "}.lst-kix_sdf0j17e1jp-1>li:before{content:"" counter(lst-ctn-kix_sdf0j17e1jp-1,lower-latin) ". "}.lst-kix_5dmkh3qp8ptx-8>li{counter-increment:lst-ctn-kix_5dmkh3qp8ptx-8}ol.lst-kix_5dmkh3qp8ptx-1.start{counter-reset:lst-ctn-kix_5dmkh3qp8ptx-1 0}ul.lst-kix_w7067k58rhkv-4{list-style-type:none}ul.lst-kix_w7067k58rhkv-3{list-style-type:none}ul.lst-kix_w7067k58rhkv-6{list-style-type:none}ul.lst-kix_w7067k58rhkv-5{list-style-type:none}ul.lst-kix_w7067k58rhkv-8{list-style-type:none}ul.lst-kix_w7067k58rhkv-7{list-style-type:none}.lst-kix_q4jiliohojpc-8>li:before{content:"\0025a0  "}.lst-kix_5dmkh3qp8ptx-1>li:before{content:"" counter(lst-ctn-kix_5dmkh3qp8ptx-1,lower-latin) ". "}.lst-kix_sdf0j17e1jp-4>li:before{content:"" counter(lst-ctn-kix_sdf0j17e1jp-4,lower-latin) ". "}.lst-kix_gxp9ru7mkj9d-7>li:before{content:"" counter(lst-ctn-kix_gxp9ru7mkj9d-7,lower-latin) ". "}.lst-kix_m9fqt5w4ua93-0>li:before{content:"\0025cf  "}.lst-kix_gxp9ru7mkj9d-6>li:before{content:"" counter(lst-ctn-kix_gxp9ru7mkj9d-6,decimal) ". "}.lst-kix_sdf0j17e1jp-4>li{counter-increment:lst-ctn-kix_sdf0j17e1jp-4}.lst-kix_m9fqt5w4ua93-4>li:before{content:"\0025cb  "}ol.lst-kix_5dmkh3qp8ptx-4.start{counter-reset:lst-ctn-kix_5dmkh3qp8ptx-4 0}.lst-kix_m9fqt5w4ua93-3>li:before{content:"\0025cf  "}ol.lst-kix_gxp9ru7mkj9d-7.start{counter-reset:lst-ctn-kix_gxp9ru7mkj9d-7 0}.lst-kix_sdf0j17e1jp-2>li:before{content:"" counter(lst-ctn-kix_sdf0j17e1jp-2,lower-roman) ". "}.lst-kix_5dmkh3qp8ptx-7>li:before{content:"" counter(lst-ctn-kix_5dmkh3qp8ptx-7,lower-latin) ". "}ol.lst-kix_5dmkh3qp8ptx-5.start{counter-reset:lst-ctn-kix_5dmkh3qp8ptx-5 0}.lst-kix_ecyay2i3donq-4>li{counter-increment:lst-ctn-kix_ecyay2i3donq-4}ul.lst-kix_w7067k58rhkv-1{list-style-type:none}.lst-kix_sdf0j17e1jp-1>li{counter-increment:lst-ctn-kix_sdf0j17e1jp-1}ul.lst-kix_w7067k58rhkv-2{list-style-type:none}ul.lst-kix_w7067k58rhkv-0{list-style-type:none}.lst-kix_ecyay2i3donq-7>li{counter-increment:lst-ctn-kix_ecyay2i3donq-7}.lst-kix_5becfkkgwd3c-5>li:before{content:"\0025a0  "}.lst-kix_87x65jl259tk-2>li:before{content:"\0025a0  "}.lst-kix_5dmkh3qp8ptx-0>li:before{content:"" counter(lst-ctn-kix_5dmkh3qp8ptx-0,decimal) ". "}ol.lst-kix_5dmkh3qp8ptx-0.start{counter-reset:lst-ctn-kix_5dmkh3qp8ptx-0 0}.lst-kix_m9fqt5w4ua93-6>li:before{content:"\0025cf  "}.lst-kix_fp64b4k8l2ok-8>li:before{content:"-  "}.lst-kix_gxp9ru7mkj9d-6>li{counter-increment:lst-ctn-kix_gxp9ru7mkj9d-6}.lst-kix_sdf0j17e1jp-3>li:before{content:"" counter(lst-ctn-kix_sdf0j17e1jp-3,decimal) ". "}.lst-kix_w7067k58rhkv-0>li:before{content:"\0025cf  "}.lst-kix_sdf0j17e1jp-3>li{counter-increment:lst-ctn-kix_sdf0j17e1jp-3}.lst-kix_ecyay2i3donq-6>li:before{content:"" counter(lst-ctn-kix_ecyay2i3donq-6,decimal) ". "}.lst-kix_ecyay2i3donq-8>li{counter-increment:lst-ctn-kix_ecyay2i3donq-8}.lst-kix_ecyay2i3donq-3>li:before{content:"" counter(lst-ctn-kix_ecyay2i3donq-3,decimal) ". "}.lst-kix_sdf0j17e1jp-5>li{counter-increment:lst-ctn-kix_sdf0j17e1jp-5}.lst-kix_ecyay2i3donq-0>li:before{content:"" counter(lst-ctn-kix_ecyay2i3donq-0,decimal) ". "}.lst-kix_5dmkh3qp8ptx-4>li{counter-increment:lst-ctn-kix_5dmkh3qp8ptx-4}.lst-kix_w7067k58rhkv-6>li:before{content:"\0025cf  "}.lst-kix_ecyay2i3donq-5>li{counter-increment:lst-ctn-kix_ecyay2i3donq-5}.lst-kix_ecyay2i3donq-3>li{counter-increment:lst-ctn-kix_ecyay2i3donq-3}.lst-kix_gxp9ru7mkj9d-1>li:before{content:"" counter(lst-ctn-kix_gxp9ru7mkj9d-1,lower-latin) ". "}.lst-kix_xorjrjr9v1ea-5>li:before{content:"\0025a0  "}ol.lst-kix_gxp9ru7mkj9d-5.start{counter-reset:lst-ctn-kix_gxp9ru7mkj9d-5 0}.lst-kix_5dmkh3qp8ptx-2>li:before{content:"" counter(lst-ctn-kix_5dmkh3qp8ptx-2,lower-roman) ". "}ol.lst-kix_sdf0j17e1jp-4.start{counter-reset:lst-ctn-kix_sdf0j17e1jp-4 0}.lst-kix_q4jiliohojpc-1>li:before{content:"\0025cb  "}.lst-kix_xorjrjr9v1ea-1>li:before{content:"\0025cb  "}.lst-kix_sdf0j17e1jp-7>li{counter-increment:lst-ctn-kix_sdf0j17e1jp-7}ol.lst-kix_sdf0j17e1jp-7.start{counter-reset:lst-ctn-kix_sdf0j17e1jp-7 0}.lst-kix_q4jiliohojpc-7>li:before{content:"\0025cb  "}ol{margin:0;padding:0}.c6{line-height:2.0;padding-top:0pt;text-align:center;padding-bottom:0pt}.c22{padding-left:0pt;padding-top:0pt;margin-left:36pt;padding-bottom:0pt}.c1{color:#252525;background-color:#ffffff;font-family:"Times New Roman"}.c24{padding-left:0pt;margin-left:36pt;padding-bottom:10pt}.c28{max-width:470.3pt;background-color:#ffffff;padding:70.9pt 70.9pt 70.9pt 70.9pt}.c0{widows:2;orphans:2;direction:ltr}.c17{background-color:#ffffff;font-family:"Roboto"}.c26{padding-left:0pt;margin-left:36pt}.c2{background-color:#ffffff;font-family:"Times New Roman"}.c10{color:#1155cc;text-decoration:underline}.c19{color:inherit;text-decoration:inherit}.c5{height:11pt;text-align:center}.c13{line-height:1.0;direction:ltr}.c23{padding-top:0pt;padding-bottom:0pt}.c29{margin:0;padding:0}.c31{text-decoration:underline}.c7{font-family:"Times New Roman"}.c12{line-height:1.15}.c27{font-family:"Roboto"}.c25{font-size:14pt}.c21{line-height:2.0}.c16{font-size:8pt}.c8{height:11pt}.c3{font-style:italic}.c15{color:#222222}.c18{padding-bottom:1pt}.c20{text-align:justify}.c4{font-size:10pt}.c14{text-align:left}.c9{font-weight:bold}.c30{line-height:1.4318181818181819}.c11{text-align:center}.title{widows:2;padding-top:0pt;line-height:1.15;orphans:2;text-align:left;color:#000000;font-size:21pt;font-family:"Trebuchet MS";padding-bottom:0pt;page-break-after:avoid}.subtitle{widows:2;padding-top:0pt;line-height:1.15;orphans:2;text-align:left;color:#666666;font-style:italic;font-size:13pt;font-family:"Trebuchet MS";padding-bottom:10pt;page-break-after:avoid}li{color:#000000;font-size:11pt;font-family:"Arial"}p{color:#000000;font-size:11pt;margin:0;font-family:"Arial"}h1{widows:2;padding-top:10pt;line-height:1.15;orphans:2;text-align:left;color:#000000;font-size:16pt;font-family:"Trebuchet MS";padding-bottom:0pt;page-break-after:avoid}h2{widows:2;padding-top:10pt;line-height:1.15;orphans:2;text-align:left;color:#000000;font-size:13pt;font-family:"Trebuchet MS";font-weight:bold;padding-bottom:0pt;page-break-after:avoid}h3{widows:2;padding-top:8pt;line-height:1.15;orphans:2;text-align:left;color:#666666;font-size:12pt;font-family:"Trebuchet MS";font-weight:bold;padding-bottom:0pt;page-break-after:avoid}h4{widows:2;padding-top:8pt;line-height:1.15;orphans:2;text-align:left;color:#666666;font-size:11pt;text-decoration:underline;font-family:"Trebuchet MS";padding-bottom:0pt;page-break-after:avoid}h5{widows:2;padding-top:8pt;line-height:1.15;orphans:2;text-align:left;color:#666666;font-size:11pt;font-family:"Trebuchet MS";padding-bottom:0pt;page-break-after:avoid}h6{widows:2;padding-top:8pt;line-height:1.15;orphans:2;text-align:left;color:#666666;font-style:italic;font-size:11pt;font-family:"Trebuchet MS";padding-bottom:0pt;page-break-after:avoid}</style></head><body class="c28"><p class="c0 c5"><span class="c2 c25"></span></p><p class="c0 c5"><span class="c2 c25"></span></p><p class="c0 c5"><span class="c2 c25"></span></p><p class="c0 c11"><span class="c2 c25">Development of </span><span class="c2 c25">Computational Epidemiological Tools to Curate Media Alerts and Predict Disease Case Counts: Application to the Recent Ebola Outbreak</span></p><p class="c0 c8"><span class="c2 c25"></span></p><p class="c0 c11"><span class="c2">Ryan Lee, Sail Wu, Jacob Zhu</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c11"><span class="c2">Instructor: Pavlos Protopapas</span></p><p class="c0 c11"><span class="c2">Teaching Fellow: Rahul Dave</span></p><p class="c0 c11"><span class="c2">Collaborator: Mauricio Santillana</span></p><p class="c0 c11"><span class="c2">AC297r, Spring 2015</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c11"><span class="c2">Project Website: </span><span class="c2 c10"><a class="c19" href="http://goo.gl/TBD">goo.gl/</a></span><span class="c2 c10"><a class="c19" href="http://goo.gl/TBD">TBD</a></span></p><p class="c0 c11"><span class="c2">Code Repository: </span><span class="c2 c10"><a class="c19" href="https://www.google.com/url?q=https%3A%2F%2Fgithub.com%2F72L%2Fsocial-media-epidemiology&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNGNyIUiiA8m7LPtRk5BoGXb7Qg8Vw">git.io/vU47j</a></span></p><p class="c0 c5"><span class="c2 c9"></span></p><p class="c0 c5"><span class="c2 c9"></span></p><p class="c0"><span class="c2 c9">Abstract</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Tools that augment official health agency reports with media data (social media in addition to traditional news media) to track the progression of a disease have been extremely valuable to epidemiologists. Our collaborators at Healthmap have developed a successful organization committed to providing up-to-date visualizations and compilations of media alerts for diseases such as Dengue fever and the flu. We contributed to three major areas of Healthmap. Firstly, we create an automatic tagging tool that organizes incoming media alerts by disease and location, easing the burden on human alert curation. Secondly, we explore novel ways to model the number of cases of a disease over time, improving their prediction so that hospitals can prepare healthcare resources in advance. We show that our tagging and prediction methods improve upon reasonable baselines by at least 10%. Lastly, we build a map and a timeline visualization that allows users to explore and learn from media data in an interactive way. Our tools improve the Healthmap process so that media data can be even more useful to epidemiologists.</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2 c9">Introduction</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Healthmap (</span><span class="c2 c31"><a class="c19" href="http://www.google.com/url?q=http%3A%2F%2Fwww.healthmap.org%2Fen%2F&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNF8vRr73PxlDhRMsNWwdNtRJdUU9A">www.healthmap.org</a></span><span class="c2">) is a collaboration between epidemiologists and computational scientists to track in real-time ongoing outbreaks of major diseases [1]. The projects emphasize the use of media data as well as official health agency reports. We use the term &ldquo;media&rdquo; broadly to refer to social media in addition to traditional news media. Media provides real-time coverage of diseases around the world much more quickly than official health reports. For instance, the use of Twitter to predict the number of cases of flu in real-time has been well studied in academia [2-4]. &nbsp;</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">A variety of sub-projects at Healthmap include predicting disease case counts based on multiple data sources (i.e. Twitter, Google Flu Trends, insurance claims) as well as visualizing cases and reports of Dengue fever. Visualizations that show when and where diseases (or reports of diseases) happen are very useful retroactively and in real time. Tools that visualize curated media reports enable epidemiologists and hospitals to better understand how a disease develops and prepare healthcare resources or advise government interventions. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Our goal for this project was to contribute useful computational tools to the Healthmap effort. We identified three major areas of Healthmap that could be improved. Firstly, we create an automatic tagging tool that organizes incoming media alerts by disease and location. Secondly, we explore novel ways to model the number of cases of a disease over time, improving their prediction. Thirdly, we build a map and timeline visualization that allows users to explore and learn from media data in an interactive way. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Human curation is currently used to organize the massive amounts of public-health-related media data scraped from the web and obtained via news feed APIs. In order to place incoming media alerts on a visualization and make the data useful, the location and date of the event mentioned in the text must be determined, along with the relevant disease. While human curation can be very accurate, it is time intensive and expensive. Our first contribution is a piece of software that is able to perform labeling automatically using machine learning. We develop and test a novel algorithm that learns the relevant vocabulary and</span><span class="c2 c3">&nbsp;</span><span class="c2">grammar </span><span class="c2">of words that indicate the importance of a mentioned location. This automated pipeline can speed up the Healthmap data cleaning and organization process by replacing human curators or acting as a first-pass curation that can reviewed quickly and efficiently by humans. This enables epidemiologists to view and use data that is as most up-to-date as possible. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Our second contribution is an improvement upon current prediction techniques used in the field. This helps epidemiologists predict the number of cases of a particular disease so that they can advise government actions. In addition, healthcare workers can better prepare for patient influx when the prediction of case counts is accurate. We improve upon current predictive models and introduce a new hidden Markov model (HMM) that is based on epidemic modelling. These approaches are tested with a data set of </span><span class="c2">Ebola-related Tweets and Ebola case/death data from the World Health Organization (WHO).</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Our last contribution is a visualization that displays the Ebola media alerts on a map and a timeline, allowing epidemiologists to discover patterns in the data at a glance. Similar visualizations already exist in Healthmap; however, we take a fresh approach by implementing new, interactive features that furthers discovery through data exploration. </span></p><p class="c0 c8"><span class="c17"></span></p><p class="c0"><span class="c2 c9">Part I. </span><span class="c2 c9">Automatic Curation of Incoming News Alerts</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">News alerts related to public health are collected with automated web scraping tools at Healthmap every day. In order to organize this massive collection of links, healthmap curators tediously label each document with relevant information such as location and disease. One of the most important goals of our current work is to make that process faster using machine learning. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Our collaborators provided a dataset of 3455 alerts, which have been curated by humans. Most of the alerts are news articles from Google News. Other media sources included ProMED, Twitter, and official government agencies like the World Health Organization (WHO). The alerts were curated and labeled with the relevant disease and the latitude and longitude of the event referenced in the article. &nbsp;The name of the location is also specified at varying levels of resolution. Some articles were labeled with an entire country, while some were tagged with more specific locations such as individual provinces or cities. The diseases mentioned were Ebola (717 alerts), influenza (1638 alerts), Dengue fever (980 alerts), and Cholera (120 &nbsp;</span><span class="c2">alerts</span><span class="c2">). The alerts were collected by Healthmap over a span of 3 months (Dec 2014 to Mar 2015). </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">The training dataset included links to each media alert, and web scraping was done to collect text data. As can be expected from scraping any web source, we encountered permissions errors and broken links. Some websites did not allow programmatic access (i.e. ProMED) while some articles were no longer visible. In addition, many of the articles had been translated through a Google Translate API which does not allow easy scraping. To solve this problem, we scraped the original article link from the Google API page and translated it ourselves using another API called goslate. After this web scraping and translation process, we ended up with usable text from 2500 alerts. </span></p><p class="c0 c8"><span class="c17"></span></p><p class="c0"><span class="c2 c3">Disease Tagging</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">We developed a tool to label each article with the disease it covers. Intuitively, one might suppose that disease tagging could be done simply by detecting disease names that occur in the text. Indeed, we use this method as a baseline for comparison. The challenge of using this naive method is that very often, text scraped from websites contain disease names that are not the main subject of the article. For instance, many disease names were found in links to other articles on the website.</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">We decided that the output of this classification task would be one disease label per media alert, since the vast majority (99.7%) of the human curated data had only one disease label per alert. So that our classifier would be able to detect alerts not mentioning any of the four disease types in our training data, we added a set of 100 news articles that were related to public health but did not cover any of the four diseases originally in our data set. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Textual data was transformed into vectors of numbers that machine learning algorithms can work with. For each article, the occurrence of a list of disease-specific words such as the disease name and words such as &ldquo;flu shot&rdquo;, &ldquo;fever&rdquo;, or &ldquo;H1N1&rdquo; were counted. Furthermore, we counted the frequency of the 5</span><span class="c2">&nbsp;</span><span class="c2">words (to the left and the right) surrounding these detected words. The words surrounding these keywords were also combined to make n-grams of length n = 1 to 5, whose frequencies were also counted. This approach enabled us to make use of some of the information in the ordering of the words around the disease keywords. A vector containing the counts of each of the n-grams detected was generated per article. The vectors, along with the human-curated disease labels were used to train a support vector classifier (SVC). &nbsp;A random forest classifier was also tested, but it did not perform as well in cross-validation testing. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Figure 1 displays our results on a receiver-operator characteristic (ROC) curve. Varied across the ROC is the </span><span class="c2">threshold of significance on the probability values generated by the classifier . These probabilities are those from an out-of-bag prediction that the article is labeled with a certain disease type. </span><span class="c2">We also show the ROC results from the baseline classifier, which is a Naive Bayes classifier trained on only the counts of the disease names in each article. &nbsp;As can be seen, our bag of n-grams SVC performs quite well, with an area under the ROC curve close to 1.00 (green line). The accuracy and precision was around 0.98 for all disease types. The area under the ROC curve for the baseline approach (blue line) is only 0.66. Therefore, our method gives a significant improvement (~30% </span><span class="c2">improvement</span><span class="c2">) over the baseline intuitive/naive classifier that utilizes only the frequency of disease names in the text. </span></p><p class="c0 c11"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 576.00px; height: 396.00px;"><img alt="disease_ROC.png" src="images/image73.png" style="width: 576.00px; height: 396.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c2 c16 c9">Figure 1. Receiver-operator characteristic (ROC) curves for the task of labeling articles with a disease type.</span><span class="c2 c16">&nbsp;The blue line shows the ROC curve from a naive method using disease name occurrences only (a Naive Bayes classifier trained with only disease names in its vocabulary). The green line shows the ROC curve from our improved method utilizing counts of n-grams surrounding disease keywords and a support vector machine (SVM) classifier. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2 c3">Location Tagging</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">The location of the subject of each media alert was determined by human curation in the training data. Some articles mentioned entire countries while some articles discussed a specific city or state. Our collaborator indicated that the automated tagging at the country resolution would be sufficient. We again developed a baseline method which only uses counts of country names in the text. While this naive method may be intuitively reasonable, it has difficulty determining the correct country when multiple countries are mentioned. Text scraped from websites often contain extraneous mentions of other country names. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Unlike disease type detection, more than 10% of media alerts in the training data are tagged with more than one country. These are articles that mention multiple countries in West Africa, for instance. Therefore, we adjusted our feature engineering and data analysis approach. A novel approach was formulated, where a trained classifier makes decisions on each location keyword mentioned in the article as opposed to the entire article (Figure 2).</span></p><p class="c0 c11"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 628.00px; height: 282.67px;"><img alt="" src="images/image70.png" style="width: 628.00px; height: 282.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c2 c9 c16">Figure 2. A novel approach to assigning multiple country labels to articles. </span><span class="c2 c16">Each document (article or alert) is scanned for mentions of country names in a list of pre-determined country names. For each mention of any country name, n-grams are extracted from the surrounding text. Each mention &nbsp;of any country name is given a binary target label indicating the correctness of the label versus human curation. The vectorised counts of the n-grams along with the binary responses are used to train a SVC that makes decisions on each mention of a country, instead of each article. A multi-label determination is made for the entire article by combining the results from each country name mention. </span></p><p class="c0 c8"><span class="c17"></span></p><p class="c0"><span class="c2">We started with a predefined list of all country names and detected the occurrence of these country names in each alert. Each mention of a country was then used as a data point in the training process. Thus, if a news article mentioned multiple countries, then that article would contribute multiple data points to our training data. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Each mention of the country was labeled with a binary target: 1 if the subject of the article pertains to the mentioned country (as verified by human curation) and 0 otherwise. As with disease classification, the five words before and after these country names were combined (in the order in which they appeared in the article) to make n-grams of sizes varying from n = 1 to 5. The n-grams were counted and this produced a vector of vocabulary counts. The vectors, along with the binary correct/incorrect labels are used to train a SVC. This approach enables the classifier to make a binary decision on each mention of a country regardless of the disease/location type, allowing us to make use of mentions of countries that occur rarely in the corpus. The classifier is then able to learn about the significance of n-grams surrounding the country names regardless of the country name, essentially learning the </span><span class="c2 c3">grammar </span><span class="c2">or </span><span class="c2 c3">vocabulary </span><span class="c2">that indicates importance. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">The multi-label prediction for the entire article is then an average of the binary decisions for each of the country name mentions in the article text. The threshold for when to call these averaged scores significant was varied and the ROC curve in Figure 3 was produced. </span></p><p class="c0 c11"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 576.00px; height: 396.00px;"><img alt="Location_ROC.png" src="images/image76.png" style="width: 576.00px; height: 396.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c2 c16 c9">Figure 3. Receiver-operator characteristic (ROC) curves for the task of labeling articles with country names. </span><span class="c2 c16">The blue line shows the ROC curve from a naive method using country name occurrences only (a Naive Bayes classifier trained with only country names in its vocabulary). The green line shows the ROC curve from our improved method utilizing counts of n-grams surrounding country names and an support vector machine classifier. </span></p><p class="c0 c8"><span class="c17"></span></p><p class="c0"><span class="c2">As can be seen, our SVC n-gram classifier performs significantly better than the intuitive approach (a Naive Bayes classifier using only country name frequency). Our n-gram and SVM classifier increases the area under the ROC curve to 0.937 (green line) which is a 16% improvement over the Naive Bayes method (area under ROC curve = 0.819). </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">This improvement, we think, comes from the classifier learning the grammar of the sentences containing these keywords. &nbsp;For example, text scraped from a webpage containing a public health article with the word &ldquo;election&rdquo; next to a country name may indicate that the country name is </span><span class="c2 c3">not </span><span class="c2">the subject of the public health article. Instead, the country may be mentioned as part of a link on the sidebar of the webpage. On the other hand, if the word &ldquo;Ebola&rdquo; is mentioned next to particular country name, then it may indicate that the country is relevant to the public health article.</span></p><p class="c0 c8"><span class="c17"></span></p><p class="c0"><span class="c2">We investigated adding HTML tag counts (such as occurrence of &ldquo;&lt;a&gt;&rdquo;) in addition to n-grams as features to improve the detection of words that are mentioned as part of sidebar links instead of in the main body of the article. This approach did not improve the area under the ROC curve significantly. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Future work on the automatic location tagging process should investigate using higher resolution location names (such as city or province names) as well as better scraping techniques to obtain higher quality textual data. </span></p><p class="c0 c8"><span class="c17"></span></p><p class="c0"><span class="c2 c3">Date Tagging</span></p><p class="c0 c8"><span class="c2 c3"></span></p><p class="c0"><span class="c2">The final goal of automatic curation of media alerts was to predict the date of the article&rsquo;s subject given its text and the date it was published. Although the date of publication is easily determined (as this information is included in news feed APIs), it is not necessarily the date of the event that the article covers. This date labeling is not currently done by the Healthmap curators. They simply store the date of publication on their website. We thought that having the actual date of the event may be useful to epidemiologists studying these news alerts. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">We established a trivial baseline method of &ldquo;predicting&rdquo; the date an alert was published as the real event date. This baseline method assumes that media alerts are always published on the same day as the event that they cover, which may be a valid assumption for many articles. To characterize the performance of the baseline method, we needed to reference the ground truth. This was done for a subsample of about 200 alerts using Amazon Mechanical Turk (MTurk). Each alert was reviewed by three MTurk workers to ensure inter-worker accuracy. We manually resolved the conflicts that arose between the workers. The difference in the number of days between each alert&rsquo;s publish date and the ground truth date obtained from MTurk readers was determined and this was used as a measure of lag or error for the baseline approach (Figure 4A). </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">To perform automatic machine prediction of the real date, we explored a variety of natural language processing (NLP) libraries that claimed to be able to extract dates from text. Since some articles use </span><span class="c2 c3">relative temporal words</span><span class="c2">&nbsp;such as &ldquo;tomorrow&rdquo; or &ldquo;last week&rdquo;. These would have to be taken into account. For example, a mention of the words &ldquo;next week&rdquo; should indicate that the real event date is around 7 days after the date the media alert was published. Of the NLP tools that we surveyed, only a tool called </span><span class="c2 c3">parsedatetime </span><span class="c2">could reliably extract these dates from the text and make use of a reference date to calculate the true date whenever it encountered relative temporal words.</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">The average lags/errors of the dates detected by </span><span class="c2 c3">parsedatetime </span><span class="c2">per article are shown in Figure 4B. There is significant error in using this approach as compared to the baseline method of just predicting the date the alert was published. The order of magnitude increase in error can be attributed to systematic mistakes in the way </span><span class="c2 c3">parsedatetime </span><span class="c2">handles relative temporal words. In addition, it was over-eager to identify any numbers detected as dates. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c13"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 628.00px; height: 228.00px;"><img alt="" src="images/image65.png" style="width: 628.00px; height: 228.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c2 c16 c9">Figure 4: Errors in the prediction of real event dates.</span><span class="c2 c16">&nbsp;The lag between the real event date (as determined by human readers from Amazon Mechanical Turk) and the predicted date was calculated as the predicted date minus the real event date. The lag (in days) is therefore positive if the article is published after the event it references, and negative if it was published before. (A) The lags of the predicted date per article using the baseline approach of predicting the publish date. (B) The lags of the predicted date per article (average over all dates detected by the NLP tool) using an NLP approach. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">We therefore decided not to pursue automatic date prediction for several reasons. The difficulty of improving the </span><span class="c2 c3">parsedatetime</span><span class="c2">&nbsp;tool is twofold. Firstly dates must be extracted accurately given the textual information. Secondly, out of the multiple possible dates extracted per article, the correct date must be picked out. Both of these tasks would have required significant work given the current state of the </span><span class="c2 c3">parsedatetime </span><span class="c2">results. Moreover, improvement work, which may or may not provide any significant gain in accuracy, may not be so helpful anyway. The data displayed in Healthmap (and often in epidemiology literature) is at a weekly resolution, and the errors of our baseline method (Figure 4A) is within 7 days. This means that the current baseline approach is probably good enough for all intensive purposes. &nbsp;Therefore, we decided to focus our attention to other aspects of the project. </span></p><p class="c0 c8"><span class="c17"></span></p><p class="c0"><span class="c2 c9">Part II. Prediction of Weekly Ebola Case Counts</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Official health organizations (i.e. WHO) report weekly case counts that are lagged by a few weeks due to the time it takes to manually count cases, sometimes over remote geographical regions. An estimate of the current weekly case count of a particular disease is extremely valuable to epidemiologists and health workers. The data allows hospitals to prepare resources accordingly to meet expected demand. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">The collaborators working at Healthmap have built tools to predict the number of cases of flu using mainly autoregressive models currently accepted in the scientific literature [5]. We apply the same models to Ebola, and make modifications which improve the prediction performance. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">We work with a dataset of geotagged Tweets obtained from the Healthmap Twitter listener, collected over the course of a year from March 2014 to March 2015. We only retrieved Tweets mentioning the term &ldquo;Ebola&rdquo; within a geographic boundary defined by a rectangle with its northwest corner at (12.91&deg; N, 15.55&deg; W) and its southwest corner at (4.06&deg; N, 7.16&deg; W). This captures all Tweets from Guinea, Sierra Leone, and Liberia (Figure 5). Since few Twitter users live in western Africa and even fewer have geo-tagging turned on, we were only working with 3126 Tweets in total. Official case counts were obtained from WHO reports online.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 628.00px; height: 268.00px;"><img alt="" src="images/image72.png" style="width: 628.00px; height: 268.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c20"><span class="c2 c16 c9">Figure 5. Geotagged Tweet data and Ebola case counts. </span><span class="c2 c16">(A) A heatmap of our geotagged Tweets. As expected, Twitter users are clustered near city centers. Areas of high Tweet density near the country center (but not corresponding to a city) are assumed to be geotagged at the country level. (B) Tweets and cases of Ebola over time for Sierra Leone, Guinea, and Liberia. There appears to be two periods of hype before and after a central peak of Ebola cases near Nov 2014. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Given the Tweets from the current week, along with the case counts from the weeks before, our goal was to predict the case counts of the current week. We first examine a baseline autoregressive model:</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0 c11"><img src="images/image00.png"></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Where </span><img src="images/image01.png"><span class="c2">&nbsp;is the number of cases in the current week, and</span><img src="images/image02.png"><span class="c2">is the number of cases i weeks before the current one. The coefficients </span><img src="images/image03.png"><span class="c2">are determined by maximum likelihood estimation with the training data. To test the appropriateness of this autoregressive (AR) model on our Ebola WHO case count data, we plotted the autocorrelation function (ACF) and partial-autocorrelation function (PACF) (Figure 6) of the data. This time series displays a AR signature, more so than that of a moving average (MA) model. The AR coefficient chosen was AR(2) since the PACF seems to die down around two (or three) lags.</span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 628.00px; height: 238.67px;"><img alt="" src="images/image67.png" style="width: 628.00px; height: 238.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c20"><span class="c2 c16 c9">Figure 6. Autocorrelation function (ACF) and Partial autocorrelation function (PACF) for Ebola cases time series. </span><span class="c2 c16">The autocorrelation and partial autocorrelation functions were used as diagnostic tools to determine the appropriateness of fit for an autoregressive (AR) and/or moving average (MA) model. The PACP declines around lag 2 or 3 while the ACF declines more slowly. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Models with an added Tweet component are often used in literature to make use of the real-time nature of social media data [5]. We use the following model to incorporate the weekly Tweets time series. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0 c11"><img src="images/image04.png"></p><p class="c0 c5"><span class="c2"></span></p><p class="c0"><span class="c2">Where</span><img src="images/image05.png"><span class="c2">&nbsp;is the number of Tweets in the current week, </span><img src="images/image06.png"><span class="c2">&nbsp;is the number of Tweets </span><span class="c2 c3">i </span><span class="c2">weeks before, and </span><img src="images/image07.png"><span class="c2">&nbsp; are parameters estimated with maximum likelihood methods. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">To improve upon the current model used in literature, we decided to add features to the data that are determined in an unsupervised manner with topic modelling and emotions keywords. Topic modelling was performed to extract a latent clustering of Tweets that probabilistically discuss different topics. A modified pLSI model (which is similar to Latent Dirichlet Allocation [6]) was used. Each Tweet is modeled as a bag of words belonging to one topic. Each of the words in the Tweet are chosen from a multinomial distribution over the vocabulary, where the distributions are determined on a per-topic basis. Expectation maximization was used in the maximum likelihood estimation of the parameters, and the number of topics (three) was chosen by inspection. This number was chosen because it seemed to produce topic words that made the most sense. A more detailed derivation can be found in the Appendix. Three topics were detected and the top words belonging in each topic were used to haracterize their &ldquo;meaning&rdquo;. Topic 1 had a high probability associated with words related to news outlet reports such as &ldquo;cases&rdquo;, &ldquo;west Africa&rdquo;, and &ldquo;news&rdquo;. Topic 2, we concluded, was mostly about vaccines and treatment, having high probability for words such as &ldquo;#giveustheserum&rdquo; and &ldquo;vaccine&rdquo;. The word &ldquo;Guinea&rdquo; had high probability in Tweets belonging to Topic 2 as well. The third topic seemed to have more general words pertaining to Ebola, and we could not make out a consistent theme. The proportion of labeled Tweets classified under each topic over time are shown in Figure 7 (bottom panel). Each Tweet was categorized as belonging to exactly one topic. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Previous work has explored adding heuristically determined categorizations of Tweets as features to improve modelling [3]. We perform a variation of this categorization by labelling the Tweets with five emotion classes that have been studied in natural language processing literature [7]. The five emotion categories are joy, sadness, anger, affection and fear. Keywords in each category were compiled from previous work [7] and Tweets containing these words were classified into their respective categories. Tweets containing words in multiple categories were counted </span><span class="c2">twic</span><span class="c2">e. Tweets not in English were translated to English. Not many Tweets were classified with emotions due to suboptimal translation and the fact that list of keywords for each emotion was not comprehensive. Tweets not labeled with an emotion were not included in the emotion time series analysis. The proportions of labeled Tweets classified under each emotion over time are shown in Figure 7 (top panel). </span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 628.00px; height: 342.67px;"><img alt="FIGURE-6-topic-and-emotions.png" src="images/image74.png" style="width: 628.00px; height: 342.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c20"><span class="c2 c16 c9">Figure 7. Detected Topic and Emotion Tweet Proportions over Time. </span><span class="c2 c16">(Top) Proportion of Tweets labeled with emotions in each emotion category, over time. Keywords identified as markers for the five emotions (joy, affection, sadness, fear, and anger) were </span><span class="c2 c16 c3">a priori</span><span class="c2 c16">&nbsp;identified and detected in Tweets. (Bottom) Proportion of Tweets that were categorized into each topic using topic modelling, during each week. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">As can be seen, the proportion of Tweets in each topic and emotion remains relatively constant over time. At the start of the outbreak, around June of 2014, the proportion of Tweets belonging to Topic 1 (Case and News Reports) seems to be high, which may indicate that news channels and official reports spoke about Ebola first, before the general population started Tweeting about it. Further investigation could look into this effect where the media plays a big role in creating hype or awareness about a particular disease. In the emotions data, there are fewer data points, so some weeks don&rsquo;t have bars. Therefore, the variation in the proportion of Tweets in each category is probably mostly noise.</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">The numbers of Tweets that fell into each emotion and topic category per week were added as features in the prediction modelling:</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0 c11"><img></p><p class="c0"><span class="c2"><br>Where</span><img src="images/image08.png"><span class="c2">&nbsp;is the number of Tweets in topic </span><span class="c2 c3">j</span><span class="c2">&nbsp;during the week </span><span class="c2 c3">i </span><span class="c2">weeks before the current week, </span><img src="images/image09.png"><span class="c2">&nbsp;is the number of Tweets with emotion </span><span class="c2 c3">j</span><span class="c2">&nbsp;during the week </span><span class="c2 c3">i </span><span class="c2">weeks before the current week, and</span><img src="images/image10.png"><span class="c2">and </span><img src="images/image11.png"><span class="c2">&nbsp;are parameters estimated with maximum likelihood methods. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">The results of the three models, starting with the baseline autoregressive model along with the two variants discussed above (one with Tweets data added and one with additional topic and emotion data added) are shown in Figure 8. </span></p><p class="c0 c23 c12 c14"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 628.00px; height: 224.00px;"><img alt="" src="images/image77.png" style="width: 628.00px; height: 224.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c23 c12 c20"><span class="c2 c16 c9">Figure 8. Results of original and improved autoregressive models.</span><span class="c2 c16">&nbsp;The accuracy of the model increases as the Tweets timeseries and the topic and emotion time series are added to the model. Adding Tweets improves the prediction by 8% and adding topics and emotions improves the prediction by 16%. </span></p><p class="c0 c23 c12 c8 c14"><span class="c2"></span></p><p class="c0 c23 c12 c14"><span class="c2">As can be seen, the baseline RMSE between the actual cases and the predicted cases is 498, which is unfortunately quite high since many of the weekly case counts sum to around 500 cases. Adding the Tweet data improves prediction by 8% overall and adding the topic and emotion modelling improves the prediction by 16%. </span></p><p class="c0 c23 c12 c8 c14"><span class="c2"></span></p><p class="c0 c23 c12 c14"><span class="c2">The jagged nature of the case and Tweet timeseries contributes to the jagged predicted cases time series as these models are autoregressive in nature. In addition, there seems to be some lag in the prediction, especially near the peak of cases between October and November 2014. This is a common artifact seen in results of autoregressive models. One of the key assumptions of such a model is stationarity of the time series. As the Ebola case data is from a disease outbreak, this assumption may not be valid because the rate of spread of this disease may change over time. Important factors varying in time such as the number of currently infected individuals, societal responses, and recovery (along with subsequent immunity) could contribute to the non-stationarity of this time series. </span></p><p class="c0 c23 c12 c8 c14"><span class="c2"></span></p><p class="c0 c23 c12 c14"><span class="c2">Moreover, we might posit that a prediction model should produce smooth results to take into account that some of the variation in the data is due to noise. (It should not predict noise.) These concerns about the autoregressive models motivated our investigation of a hidden Markov model (HMM).</span></p><p class="c0 c23 c12 c8 c14"><span class="c2 c3"></span></p><p class="c0 c23 c12 c14"><span class="c2 c3">Hidden Markov </span><span class="c2 c3">Model</span></p><p class="c0 c23 c12 c8 c14"><span class="c2 c3"></span></p><p class="c0 c12 c14 c23"><span class="c2">We propose a hidden Markov model shown in Figure 9A. At each time point, there are 4 hidden states that correspond to 4 different populations. We use the well known SEIR epidemic model [8-10] to model the dynamics of the Ebola outbreak. The state </span><img src="images/image12.png"><span class="c2">&nbsp;represents the population susceptible to Ebola at time </span><img src="images/image13.png"><span class="c2">. </span><span class="c2">The state </span><img src="images/image14.png"><span class="c2">represents the population that has been exposed to Ebola but is not infectious at time </span><img src="images/image13.png"><span class="c2">.</span><span class="c2">&nbsp;The state </span><img src="images/image15.png"><span class="c2">represents the population that is infected and infectious at time </span><img src="images/image13.png"><span class="c2">. The state </span><img src="images/image16.png"><span class="c2">represents the population that has recovered at time </span><img src="images/image13.png"><span class="c2">. A proportion of these R cases are those who are dead. People flow through the 4 possible states in the order: S to E to I to R, and the rates of change of the proportion of the entire population in each state is well described by known differential equations [8]. The differential equations describing the dynamics of the SEIR model were discretized as has been done similarly in others&rsquo; work [11], as follows:</span></p><p class="c0 c23 c12 c8 c14"><span class="c2"></span></p><p class="c6 c0"><img src="images/image17.png"></p><p class="c6 c0"><img src="images/image18.png"></p><p class="c0 c6"><img src="images/image19.png"></p><p class="c6 c0"><img src="images/image20.png"></p><p class="c0 c23 c12 c14"><span class="c2">Where </span><img src="images/image21.png"><span class="c2">&nbsp;is a parameter determining the rate of exposure (people moving from the susceptible the exposed group), </span><img src="images/image22.png"><span class="c2">&nbsp;is a parameter determining the incubation period (which affects movement from the exposed the infectious group), and </span><img src="images/image23.png"><span class="c2">&nbsp;is a parameter determining the rate of recovery (or death) (moving from the infectious the recovered/dead group). Initial conditions of the SEIR model are another parameter that must be determined. </span></p><p class="c0 c23 c12 c8 c14"><span class="c1"></span></p><p class="c0 c12 c18"><span class="c1">We initially used a deterministic model for the hidden states, where the proportions of the population in each of the four SEIR states were determined for each time step using the above equations. We used three emitted states, with Gaussian emission probabilities:</span></p><p class="c0 c8 c18 c30"><span class="c1"></span></p><p class="c0 c21 c18 c11"><img src="images/image24.png"><span class="c2">&nbsp;</span></p><p class="c0 c21 c18 c11"><img src="images/image25.png"></p><p class="c0 c21 c18 c11"><img src="images/image26.png"></p><p class="c0 c23 c12 c14"><span class="c1">where </span><img src="images/image27.png"><span class="c2">&nbsp;is the number of Tweets on week </span><img src="images/image13.png"><span class="c2">, </span><img src="images/image01.png"><span class="c2">&nbsp;is the number of cases reported by the WHO on week </span><img src="images/image13.png"><span class="c2">, and </span><img src="images/image28.png"><span class="c2">&nbsp;is the number of deaths reported by the WHO on week </span><img src="images/image13.png"><span class="c2">. The parameters </span><img src="images/image29.png"><span class="c2">, </span><img src="images/image30.png"><span class="c2">, </span><img src="images/image31.png"><span class="c2">,</span><img src="images/image32.png"><span class="c2">,</span><img src="images/image33.png"><span class="c2">, and </span><img src="images/image34.png"><span class="c2">govern the Gaussian emission probabilities and the parameters </span><img src="images/image35.png"><span class="c2">,</span><img src="images/image36.png"><span class="c2">, and </span><img src="images/image37.png"><span class="c2">govern the SEIR transition (and its initial conditions). These were all determined with maximum likelihood estimation. (See Appendix for details.) The RMSE of the number of cases predicted by the deterministic model compared to the official case counts is 474 cases. This is comparable to the performance of the autoregressive models. </span></p><p class="c0 c23 c12 c8 c14"><span class="c1"></span></p><p class="c0 c23 c12 c14"><span class="c1">To create a &ldquo;true&rdquo; hidden Markov model, we added transition probabilities to the hidden state transitions in the SEIR model:</span></p><p class="c0 c21 c11"><img src="images/image38.png"></p><p class="c0 c21 c11"><img src="images/image39.png"></p><p class="c0 c21 c11"><img src="images/image40.png"></p><p class="c0 c21 c11"><img src="images/image41.png"></p><p class="c0 c23 c12 c14"><span class="c2">where </span><img src="images/image42.png"><span class="c2">&nbsp;models Gaussian noise in the transition to the next state</span><img src="images/image43.png"><span class="c2">. Newly introduced hidden transition parameters were also fitted using maximum likelihood estimation (See Appendix for details). The RMSE of the number of cases predicted by this model (with transition probabilities added) compared to the official case counts is 472 cases. This is comparable to the performance of the deterministic HMM and the autoregressive models. The results are shown in Figure 9B. </span></p><p class="c0 c23 c12 c8 c14"><span class="c2"></span></p><p class="c0 c23 c12 c14"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 628.00px; height: 192.00px;"><img alt="" src="images/image68.png" style="width: 628.00px; height: 192.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c23 c12 c20"><span class="c2 c16 c9">Figure 9. HMM and results. </span><span class="c2 c16">(A) Our hidden Markov model assumes 4 hidden states modelling the susceptible (S), exposed (E), infected (I), and recovered (R) populations. Hidden states transition according to the well-studied epidemiology SEIR model, with Gaussian error. Observed states are the number of Tweets (T), the number of reported cases (C), and the number of reported deaths (D). The emission probability was assumed to be Gaussian. (B) Results from the HMM model shows that we are able to trace the cases and the deaths relatively smoothly. </span></p><p class="c0 c8"><span class="c7"></span></p><p class="c0"><span class="c7">Compared to autoregressive models, the RMSE of the case predictions are similar. However, the RMSE is calculated assuming that the WHO numbers are the ground truth, when there is obviously quite some noise in their reporting. Our generative, Bayesian approach assumes an underlying model that takes into account the dynamics of an outbreak. It then assigns a probability distribution to observed Tweet, case, and death counts. This is able to therefore produce predictions that are smoother, without the noise seen in Figure 8. In this sense, this HMM is a better model in that it is able to reason about our belief of the truth of the number of cases and deaths vs. relying on noisy numbers reported by the WHO.</span></p><p class="c0 c8"><span class="c7"></span></p><p class="c0"><span class="c7">Most importantly, we are able to provide epidemiologists with an estimate of the parameters </span><img src="images/image35.png"><span class="c2">,</span><img src="images/image36.png"><span class="c2">, and </span><img src="images/image37.png"><span class="c2">&nbsp;</span><span class="c7">describing the underlying outbreak dynamics, which would be extremely useful in forecasting future cases or in comparing the dynamics of different outbreaks across regions. </span></p><p class="c0 c8"><span class="c7"></span></p><p class="c0"><span class="c7">In addition, the HMM was optimized by maximising the likelihood of observing three data sets (Tweets, cases, and deaths), whereas the autoregressive models were only fitted to the cases data. This means that our HMM approach is more general and may have produced even better results if it were not also optimized to explain the Tweets data. </span><span class="c7">Indeed, removing the Tweets component improves the case-count RMSE by about 4. </span></p><p class="c0 c8"><span class="c7"></span></p><p class="c0"><span class="c7">We understand that there are limitations of the current assumptions of this HMM. Firstly, we assumed that the Tweets are proportional to the number of infected people. </span><span class="c7">However, in reality, Tweets could also be dependent on the proportion of the population in the exposed (E) state in addition to just the proportion of the population in the infected (I) state. Furthermore, the number of Tweets in the previous week may play a large role in determining the number of Tweets in the next week (accounting for hype and network effects). </span><span class="c7">Future work should investigate adding these complex dependencies to the model. &nbsp;</span></p><p class="c0 c8"><span class="c27"></span></p><p class="c0"><span class="c2 c9">Part III. </span><span class="c2 c9">Visualization of Curated Media Reports Covering Ebola</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">We built a tool for data visualization and exploration so that the curated media data could be explored by epidemiologists with ease. The tool is a Javascript-powered visualization that takes as input a JSON file of data that has been curated by humans or the tagging tool discussed above. It automatically generates a responsive webpage that is interactive and intuitive to use. Figure 9 highlights selected features of the webpage that is created. The demo we built uses a set of Ebola media alerts from March 2014 to March 2015. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">There are two main parts of the visualization. The map portion displays the locations of the media alerts, allowing users to pan and zoom around the world to see which locations are being covered by the media. The timeline portion displays the number of disease cases and deaths along with the volume of incoming alerts, allowing users to visualize media &ldquo;hype&rdquo; as the disease progresses. Both the timeline and the map are interactive, so adjusting the time window displayed using the timeline navigation window updates both parts of the visualization. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">We used a Javascript package called AMCharts to display the information on a map and on a timeline. Multiple custom modifications to the Javascript code were made to make the display interactive. For instance, a custom modification was added so that a user&rsquo;s actions on the timeline immediately led to updates on the map reflecting those temporal changes. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0 c11"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 508.30px; height: 723.50px;"><img alt="FIGURE-9---visualization.png" src="images/image64.png" style="width: 508.30px; height: 723.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c20"><span class="c2 c16 c9">Figure 10. Visualization web page displaying curated media data for Ebola. </span><span class="c2 c16">Here, we highlight three major features of the visualization and data exploration tool. (A) Each dot represents a location reported by alerts, and clicking on them brings up a panel of alert links. The map allows the user to pan and zoom to discover alerts at other areas around the world. The squares are shown for alerts that covering entire countries in general, instead of a specific provinces or cities. The opacity of the squares and dots represent the relative number of alerts for that location. (B) There is an interactive timeline beneath the map displaying the number of cumulative cases and deaths, as well as the number of alerts per day. The user can choose to display the non-cumulative graphs of the cases and deaths as well. Using the overview timeline window at the top, the user can zoom to different sections in time to examine the fine details. (C) Moving the sliders on the overview timeline window will also update the map alerts, so that the user can generate an animation that displays the spread of alerts over time. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2 c9">Conclusion</span></p><p class="c0 c8"><span class="c17"></span></p><p class="c0"><span class="c2">Our goal for this project was to contribute useful computational tools to the Healthmap effort. We identified three major areas of the Healthmap process that could be improved. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">First, we created an automatic tagging tool that tags incoming media alerts by disease and location. We showed that our tagging tool produced a 30% and 16% improvement over baseline methods for disease and location tagging, respectively. We believe this tool has the ability to make an enormous impact by cutting the amount of time it takes human curators to manually curate media alerts. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Secondly, we improved upon currently accepted autoregressive predictive models by adding features learned in an unsupervised manner from the text. These modifications reduced the prediction error by 16% compared to the baseline. We also introduced a hidden Markov model that models the dynamics of the outbreak and incorporates a natural way to think about how Tweets and official case counts are generated probabilistically. This model is able to perform comparably to the autoregressive models currently used by epidemiologists. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">Thirdly, we built a map and timeline visualization that allows users to explore and learn from media data in an interactive way. Users who tried this tool expressed delight at the responsive interactivity of the website that enabled them to visualize the spread of media attention geographically and temporally. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">This project had multiple learning outcomes that enriched our educational experience. Several of the techniques used in this project were completely new to us when we started. These included topic modelling, hidden Markov modelling, and the Javascript visualization library called AMCharts. This project gave us the opportunity to experience the full stack of the data science process, from raw data organization and labelling, to prediction, and to visualization. In the end, we were able to provide three major contributions to our collaborators at Healthmap who will be able to use our tools to better serve epidemiologists and hospitals fighting disease. </span></p><p class="c0 c8"><span class="c17"></span></p><p class="c0"><span class="c2 c9">Acknowledgements</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">We would like to thank the AC297r staff, especially Pavlos and Rahul for their support and guidance. We would like to thank Nico Preston, Wesley Chen, and Jared Hawkins for their help in obtaining data from Healthmap databases and advice regarding previous Healthmap work. We would like to thank Kriste Krstovski for helpful discussion about topic modelling. This work would not have been possible or as enjoyable without the engaging discussions we had with faculty, staff, and our fellow students at IACS. </span></p><p class="c0 c8"><span class="c17"></span></p><p class="c0 c8"><span class="c2 c9"></span></p><p class="c0 c8"><span class="c2 c9"></span></p><p class="c0 c8"><span class="c2 c9"></span></p><p class="c0 c8"><span class="c2 c9"></span></p><p class="c0"><span class="c2 c9">References</span></p><p class="c0 c8"><span class="c2 c9"></span></p><ol class="c29 lst-kix_ecyay2i3donq-0 start" start="1"><li class="c24 c0"><span class="c2 c15">Brownstein, J. S., Freifeld, C. C., Reis, B. Y., &amp; Mandl, K. D. (2008). Surveillance Sans Frontieres: Internet-based emerging infectious disease intelligence and the HealthMap project. </span><span class="c2 c3 c15">PLoS medicine</span><span class="c2 c15">, </span><span class="c2 c3 c15">5</span><span class="c2 c15">(7), e151.</span></li><li class="c24 c0"><span class="c2 c15">Achrekar, H., Gandhe, A., Lazarus, R., Yu, S. H., &amp; Liu, B. (2011, April). Predicting flu trends using twitter data. In </span><span class="c2 c3 c15">Computer Communications Workshops (INFOCOM WKSHPS), 2011 IEEE Conference on</span><span class="c2 c15">&nbsp;(pp. 702-707). IEEE.</span></li><li class="c24 c0"><span class="c2 c15">Lamb, A., Paul, M. J., &amp; Dredze, M. (2013, June). Separating Fact from Fear: Tracking Flu Infections on Twitter. In </span><span class="c2 c3 c15">HLT-NAACL</span><span class="c2 c15">&nbsp;(pp. 789-795).</span></li><li class="c24 c0"><span class="c2 c15">Culotta, A. (2010, July). Towards detecting influenza epidemics by analyzing Twitter messages. In </span><span class="c2 c3 c15">Proceedings of the first workshop on social media analytics</span><span class="c2 c15">&nbsp;(pp. 115-122). ACM.</span></li><li class="c0 c24"><span class="c2 c15">Nagar, R., Yuan, Q., Freifeld, C. C., Santillana, M., Nojima, A., Chunara, R., &amp; Brownstein, J. S. (2014). A Case Study of the New York City 2012-2013 Influenza Season With Daily Geocoded Twitter Data From Temporal and Spatiotemporal Perspectives. </span><span class="c2 c3 c15">Journal of medical Internet research</span><span class="c2 c15">, </span><span class="c2 c3 c15">16</span><span class="c2 c15">(10).</span></li><li class="c24 c0"><span class="c2 c15">Mei, Q., &amp; Zhai, C. (2001). A note on EM algorithm for probabilistic latent semantic analysis. In </span><span class="c2 c3 c15">Proceedings of the International Conference on Information and Knowledge Management, CIKM</span><span class="c2 c15">.</span></li><li class="c24 c0"><span class="c2 c15">Qadir, A., &amp; Riloff, E. Learning Emotion Indicators from Tweets: Hashtags, Hashtag Patterns, and Phrases.</span></li><li class="c24 c0"><span class="c2 c15">Hethcote, H. W. (2000). The mathematics of infectious diseases. </span><span class="c2 c3 c15">SIAM review</span><span class="c2 c15">,</span><span class="c2 c3 c15">42</span><span class="c2 c15">(4), 599-653.</span></li><li class="c24 c0"><span class="c2 c15">Wearing, H. J., Rohani, P., &amp; Keeling, M. J. (2005). Appropriate models for the management of infectious diseases. </span><span class="c2 c3 c15">PLoS medicine</span><span class="c2 c15">, </span><span class="c2 c3 c15">2</span><span class="c2 c15">(7), e174.</span></li><li class="c24 c0"><span class="c2 c15">Lekone, P. E., &amp; Finkenst&auml;dt, B. F. (2006). Statistical inference in a stochastic epidemic SEIR model with control intervention: Ebola as a case study.</span><span class="c2 c3 c15">Biometrics</span><span class="c2 c15">, </span><span class="c2 c3 c15">62</span><span class="c2 c15">(4), 1170-1177.</span></li><li class="c24 c0"><span class="c2 c15">Pasquali, C. &nbsp;(2014). On the SIR Equations and Their Transform into a Markov Transition Matrix (or, the Markovization of the SIR Model). </span><span class="c2 c3 c15">The Pasqualian</span><span class="c2 c15">, http://thepasqualian.com/?p=1862.</span></li></ol><p class="c0 c8"><span class="c17 c9"></span></p><p class="c0 c8"><span class="c17 c9"></span></p><p class="c0 c8"><span class="c17 c9"></span></p><p class="c0 c8"><span class="c2 c9"></span></p><hr style="page-break-before:always;display:none;"><p class="c0 c8"><span class="c2 c9"></span></p><p class="c0"><span class="c2 c9">Appendix</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2 c3">Topic Modelling</span></p><p class="c0 c8"><span class="c2 c3"></span></p><p class="c0"><span class="c2">For topic modelling, w</span><span class="c2">e assume the probabilistic generative process for Tweets shown in Figure A1. This is similar to a topic model found in literature called the pLSI model [6]. This is a simpler model than the more well-known topic model Latent Dirichlet Allocation. We thought this was appropriate because Tweets are significantly shorter than most documents so we model each Tweet as belong to one topic only. </span></p><p class="c0 c11"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 198.50px; height: 216.74px;"><img alt="" src="images/image66.png" style="width: 198.50px; height: 216.74px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c20"><span class="c2 c16 c9">Figure A1. Probabilistic topic model used to detect topics in Tweets. </span><span class="c2 c16">Each of the </span><img src="images/image44.png"><span class="c2 c16">&nbsp;Tweets is assigned a topic </span><img src="images/image45.png"><span class="c2 c16">&nbsp;chosen from the multinomial distribution specified by </span><img src="images/image46.png"><span class="c2 c16">. The multinomial distribution over the vocabulary words for the topic </span><img src="images/image45.png"><span class="c2 c16">is parameterized by </span><img src="images/image47.png"><span class="c2 c16">. Each word in the document is then chosen from the multinomial distribution specified by </span><img src="images/image48.png"><span class="c2 c16">.</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">This is an unsupervised method with the goal of creating features, rather than a predictive method used to predict the topic of new tweets. Therefore, priors were not necessary. It is not very generalizable to Tweets discussing topics that have not been seen before. However, we assume that in practice, the topic model would be re-fitted frequently to discover new topic as new Tweet data is added. Due to the simplicity of the model and the way we solve for the parameters, re-fitting is not expected be a significant computational burden.</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">To solve for the maximum likelihood estimates of the parameters given the data, we used expectation maximization. In the E-step, we estimate the </span><img src="images/image45.png"><span class="c2">and in the M-step, we maximize the complete data log likelihood holding the </span><img src="images/image45.png"><span class="c2">estimates constant. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">In the E-step, we define a variable called </span><img src="images/image49.png"><span class="c2">that is our estimate of the </span><img src="images/image45.png"><span class="c2">. We set </span><img src="images/image50.png"><span class="c2">&nbsp;since this is the best estimate of </span><img src="images/image45.png"><span class="c2">&nbsp;and minimizes the K-L divergence between </span><img src="images/image49.png"><span class="c2">&nbsp;and </span><img src="images/image51.png"><span class="c2">&nbsp;where </span><img src="images/image52.png"><span class="c2">represents the data and </span><img src="images/image53.png"><span class="c2">represents the parameters. This maximizes the lower bound on our estimate of the log likelihood of the data given the parameters. It can then be shown that</span><img src="images/image54.png"><span class="c2">, our current estimate.probability that </span><img src="images/image55.png"><span class="c2">(Tweet </span><img src="images/image56.png"><span class="c2">&nbsp;belongs to topic </span><img src="images/image57.png"><span class="c2">) is:</span></p><p class="c0 c11"><img src="images/image58.png"></p><p class="c0"><span class="c2">where </span><img src="images/image59.png"><span class="c2">is the vector of word counts for Tweet </span><img src="images/image56.png"><span class="c2">&nbsp;over the vocabulary, </span><img src="images/image60.png"><span class="c2">is the proportion of all Tweets in topic topic </span><img src="images/image57.png"><span class="c2">, and </span><img src="images/image48.png"><span class="c2">is a vector of probabilities defining a multinomial distribution over words in the vocabulary for topic </span><img src="images/image57.png"><span class="c2">.</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">In the M-step, we maximize the following complete data log likelihood with respect to the parameters of the model </span><img src="images/image46.png"><span class="c2">and </span><img src="images/image61.png"><span class="c2">, using the estimates </span><img src="images/image49.png"><span class="c2">&nbsp;in place of </span><img src="images/image45.png"><span class="c2">.</span></p><p class="c0 c11"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 397.50px; height: 52.30px;"><img alt="" src="images/image71.png" style="width: 397.50px; height: 52.30px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c2">Setting the derivatives equal to zero with respect to each of the parameters and solving results in the formulas for </span><img src="images/image46.png"><span class="c2">and </span><img src="images/image61.png"><span class="c2">in the M-step.</span></p><p class="c0 c11"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 111.00px; height: 25.87px;"><img alt="" src="images/image69.png" style="width: 111.00px; height: 25.87px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c11"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 121.50px; height: 28.35px;"><img alt="" src="images/image63.png" style="width: 121.50px; height: 28.35px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">We begin the EM algorithm by setting a uniform probability of the documents belonging to each topic (uniform </span><img src="images/image46.png"><span class="c2">) and setting </span><img src="images/image61.png"><span class="c2">to random Gaussian noise. Alternating E and M steps are then performed until the top words in each topic have converged. Multiple runs are performed with different initializations to check for convergence to the same minimum. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">K, the total number of topics in the corpus was varied and the results were checked for reasonableness by inspection. K = 3 worked well for Ebola and K = 5 worked well for Chikungunya. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">For Ebola, K = 3 topics was used and the words with the highest probability in each topic are as follows:</span></p><ol class="c29 lst-kix_nx633fdz6tnz-0 start" start="1"><li class="c0 c26"><span class="c2 c4">sierraleone leone sierra outbreak cases guinea amp africa new news now treatment west fight</span></li><li class="c0 c26"><span class="c2 c4">de guin&eacute;e news un guinea giveustheserum vaccine africa trial virus via conakry health just</span></li><li class="c0 c26"><span class="c2 c4">sierra leone monrovia sierraleone today fight ebolaoutbreak amp de health us virus god people</span></li></ol><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">For Chikungunya, , K = 5 topics was used and the words with the highest probability in each topic are as follows:</span></p><ol class="c29 lst-kix_xorjrjr9v1ea-0 start" start="1"><li class="c22 c0 c12 c14"><span class="c2 c4">co http mosquito te m&aacute;s pico espero gente chinkungunya est&aacute; pic&oacute; mosquitos virus</span></li><li class="c22 c0 c12 c14"><span class="c2 c4">the co 10 http in fault our te trndnl 2014 mosquitos ast q2h6ksmyr0 quebradillas</span></li><li class="c22 c0 c12 c14"><span class="c2 c4">te chikunguya dengue mosquito mami espero mosquitos siento madre mierda ebola voy pa</span></li><li class="c22 c0 c12 c14"><span class="c2 c4">co http chinkunguya virus mosquito via estafa pico chikungu&ntilde;a to youtube carlos amodei</span></li><li class="c0 c12 c14 c22"><span class="c2 c4">co http tu virus mosquito salud frente tiran puerto rico soy pa casos dengue</span></li></ol><p class="c0 c8"><span class="c17"></span></p><p class="c0"><span class="c2 c3">Hidden Markov Model Likelihood Functions</span></p><p class="c0 c8"><span class="c2 c9"></span></p><p class="c0 c18"><span class="c2">For the model with the deterministic SEIR transitions, we assume </span><span class="c1">Gaussian emission probabilities for the three emitted states:</span></p><p class="c0 c21 c18 c11"><img src="images/image24.png"><span class="c2">&nbsp;</span></p><p class="c0 c21 c18 c11"><img src="images/image25.png"></p><p class="c0 c18 c11 c21"><img src="images/image26.png"></p><p class="c0 c21 c18"><span class="c2">Therefore, the total log likelihood to be maximized is:</span></p><p class="c0 c21 c18 c11"><img></p><p class="c0"><span class="c2">For the &ldquo;true&rdquo; HMM model, we assume additional </span><span class="c1">Gaussian error to the hidden state. </span></p><p class="c0 c21 c11"><img src="images/image38.png"></p><p class="c0 c21 c11"><img src="images/image39.png"></p><p class="c0 c21 c11"><img src="images/image40.png"></p><p class="c0 c21 c11"><img src="images/image41.png"></p><p class="c0 c12"><span class="c2">Thus, in calculating the joint likelihood, we need to marginalize out the value of the hidden state. We integrate from </span><img src="images/image15.png"><span class="c2">= 0 to 1 because the SEIR model models the </span><span class="c2 c3">proportion </span><span class="c2">of the population in each SEIR compartment. For example, the likelihood of the cases component of the model is:</span></p><p class="c0 c12 c8"><span class="c2"></span></p><p class="c0 c12 c11"><img></p><p class="c0 c5 c12"><span class="c2"></span></p><p class="c0 c12 c11"><img></p><p class="c0 c12 c8"><span class="c2"></span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">The log is taken to get a log likelihood, and the likelihood of each datum (over each week and for Tweets, cases, and deaths) can combined due to independence assumptions to create the total log likelihood function to can be maximized:</span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0 c11"><img src="images/image62.png"><span class="c2"><br></span></p><p class="c0"><span class="c2">Log likelihood maximization was done with constrained sequential least squares programming using Scipy.</span></p><p class="c0 c5"><span class="c2"></span></p><p class="c0 c14"><span class="c2 c3">HMM Hidden State SEIR Results</span></p><p class="c0 c8 c14"><span class="c2 c3"></span></p><p class="c0 c14"><span class="c2">We show that our discretization of the well-known SEIR model is able to produce reasonable curves showing outbreak dynamics (Figure A2). In Figure A2, we take the epidemic model parameters and produce the expected curves showing the proportion of the population in each SEIR compartment. The proportion of infected and exposed individuals remains low over time, which reflects well the expected number of confirmed cases out of the population of the three West African countries. </span></p><p class="c0 c8 c14"><span class="c2"></span></p><p class="c0 c14"><span class="c2">However, the model predicts that after 52 weeks, the proportion of the population in the recovered compartment is about 50%. This is not realistic, as the Ebola case counts do not reach that level in reality. We can rationalize this by assuming that the total population is not the total population of the country, but rather the population that can be potentially be infected by the disease (those living in dense urban areas or in close contact with infected individuals). In any case, the progression of the curve (its rate of change as opposed to the absolute percentage) is more telling, as it indicates that the period of rapid increase in the number of Ebola cases has past. </span></p><p class="c0 c8 c14"><span class="c2"></span></p><p class="c0 c14"><span class="c2">We also must acknowledge the imperfect assumptions in the model such as those mentioned in the report above as well as the fact that we are modelling the disease for three countries combined. Future work should focus on each country by itself as the conditions (population density, government response, etc.) may be different for each country. </span></p><p class="c0 c8 c14"><span class="c2"></span></p><p class="c0 c8 c14"><span class="c2"></span></p><p class="c0 c11"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 419.50px; height: 301.93px;"><img alt="" src="images/image78.png" style="width: 419.50px; height: 301.93px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c2 c16 c9">Figure A2. SEIR model results for Ebola.</span><span class="c2 c16">&nbsp;The proportion of the total population in each of the SEIR compartments is shown. The results shown are produced from a SEIR model with parameters estimated using the HMM modelling. </span></p><p class="c0 c8"><span class="c17 c3"></span></p><p class="c0"><span class="c2 c3">Performance of Autoregressive Models on Chikungunya Cases</span></p><p class="c0 c8"><span class="c2 c3"></span></p><p class="c0"><span class="c2">Our collaborator also provided us with Tweet data on the recent outbreak of Chikungunya fever in Puerto Rico. Chikungunya is a mild viral disease spread by mosquitos. Symptoms include fever and joint pain. The mortality rate is less than 0.1%. As advised by our collaborator, we predicted the suspected cases of Chikungunya because the suspected case count is more useful to hospitals preparing for patient influx. Suspected case data were not readily available for Ebola so it was not used in the main project. Results of the a</span><span class="c2">utoregressive models are shown in Figure A3. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 628.00px; height: 444.00px;"><img alt="" src="images/image75.png" style="width: 628.00px; height: 444.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c0"><span class="c2 c16 c9">Figure A3. Autoregressive modelling on Chikungunya case data. </span><span class="c2 c16">(A) Results of pure and improved autoregressive models. The accuracy of the model increases as the Tweets time series and the topic and emotion time series are added to the model. Adding Tweets improves the prediction by 14% and adding topics and emotions improves the prediction by 26%. (B) The ACF and (C) the PACF of the cases data are shown, indicating that a AR(2) model is appropriate. </span></p><p class="c0 c8"><span class="c2"></span></p><p class="c0"><span class="c2">We also attempted to apply the HMM modelling to the Chikungunya data. However, the model did not fit very well (as determined by inspection of the resulting predicted curves). This may be due to the difference in the way the two diseases spread. While Ebola spreads from human to human (and the SEIR model works well in this case), Chikungunya is spread from human to mosquito to human. Thus, fundamental assumptions about our model dynamics must be changed. Future work should explore a model other than SEIR for HMM modelling of Chikungunya cases. </span></p><div><p class="c0 c5"><span class="c7"></span></p></div></body></html>